<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zijie Huang</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zijie Huang (黄子倢)</name>
              </p>
              <p>I am currently a Ph.D. student at University of Calofornia, Los Angeles (UCLA), where I am fortunate to be advised by Prof.<a href="http://web.cs.ucla.edu/~yzsun/index.html">Yizhou Sun</a> and Prof.<a href="http://web.cs.ucla.edu/~weiwang/">Wei Wang</a>. My research interest lies in graph neural networks and machine learning in general. 
              </p>
              <p>
                Before joinging UCLA, I received my bachelor's degree of Information Engineering from Shanghai Jiao Tong University in 2019.
              </p>
              <p style="text-align:center">
                <a href="mailto:zijiehuang@cs.ucla.edu">Email</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/zijie-huang-62514a177/">linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/ZijieH">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="figures/zijie.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="figures/zijie.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>



        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
              <p>
                <papertitle>University of California Los Angeles, Los Angeles, CA</papertitle>
                <br> Ph.D. Student in Computer Science, 2019.9 - Present
              </p>
            </td>
          </tr>
        </tbody></table>


        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I'm interested in computer vision, machine learning, optimization, and image processing. Much of my research is about inferring the physical world (shape, motion, color, light, etc) from images. Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr onmouseout="mipnerf_stop()" onmouseover="mipnerf_start()"  bgcolor="#ffffd0">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='mipnerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/mipnerf_ipe_yellow.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/mipnerf_ipe_yellow.png' width="160">
              </div>
              <script type="text/javascript">
                function mipnerf_start() {
                  document.getElementById('mipnerf_image').style.opacity = "1";
                }

                function mipnerf_stop() {
                  document.getElementById('mipnerf_image').style.opacity = "0";
                }
                mipnerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://jonbarron.info/mipnerf">
                <papertitle>Mip-NeRF: A Multiscale Representation for Anti-Aliasing Neural Radiance Fields</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <a href="http://matthewtancik.com/">Matthew Tancik</a>, <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://jonbarron.info/mipnerf">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.13415">arXiv</a>
              /
              <a href="https://youtu.be/EpH175PY1A0">video</a>
							/
              <a href="https://github.com/google/mipnerf">code</a>
              <p></p>
              <p>NeRF is aliased, but we can anti-alias it by casting cones and prefiltering the positional encoding function.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfbake_stop()" onmouseover="nerfbake_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfbake_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfbake_15.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfbake_160.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfbake_start() {
                  document.getElementById('nerfbake_image').style.opacity = "1";
                }

                function nerfbake_stop() {
                  document.getElementById('nerfbake_image').style.opacity = "0";
                }
                nerfbake_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nerf.live">
              <papertitle>Baking Neural Radiance Fields for Real-Time View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://phogzone.com/">Peter Hedman</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://nerf.live">project page</a>
              /
              <a href="https://arxiv.org/abs/2103.14645">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=5jKry8n5YO8">video</a>
              /
              <a href="https://nerf.live/#demos">demo</a>
              <p></p>
              <p>Baking a trained NeRF into a sparse voxel grid of colors and features lets you render it in real-time in your browser.</p>
            </td>



          <tr onmouseout="nerfie_stop()" onmouseover="nerfie_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfie_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfie_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfie_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfie_start() {
                  document.getElementById('nerfie_image').style.opacity = "1";
                }
                function nerfie_stop() {
                  document.getElementById('nerfie_image').style.opacity = "0";
                }
                nerfie_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerfies.github.io/">
                <papertitle>Nerfies: Deformable Neural Radiance Fields</papertitle>
              </a>
              <br>
              
              <a href="https://keunhong.com">Keunhong Park</a>,
              <a href="https://utkarshsinha.com">Utkarsh Sinha</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://sofienbouaziz.com">Sofien Bouaziz</a>, <br>
              <a href="https://www.danbgoldman.com">Dan B Goldman</a>,
              <a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>,
              <a href="http://www.ricardomartinbrualla.com">Ricardo-Martin Brualla</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://nerfies.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2011.12948">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA">video</a>
              <p></p>
              <p>Building deformation fields into NeRF lets you capture non-rigid subjects, like people.
              </p>
            </td>
          </tr> 


          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/c5_after.jpg' width="160"></div>
                <img src='images/c5_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.11890">
                <papertitle>Cross-Camera Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/corp/view/mafifi">Mahmoud Afifi</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.linkedin.com/in/fbleibel/">Francois Bleibel</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>
                With some extra (unlabeled) test-set images, you can build a hypernetwork that calibrates itself at test time to previously-unseen cameras.
              </p>
            </td>
          </tr> 


          <tr onmouseout="nerd_stop()" onmouseover="nerd_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerd_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerd_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerd_160.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerd_start() {
                  document.getElementById('nerd_image').style.opacity = "1";
                }

                function nerd_stop() {
                  document.getElementById('nerd_image').style.opacity = "0";
                }
                nerd_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://markboss.me/publication/2021-nerd/">
                <papertitle>NeRD: Neural Reflectance Decomposition from Image Collections</papertitle>
              </a>
              <br>

              <a href="https://markboss.me">Mark Boss</a>, 
              <a href="https://uni-tuebingen.de/en/fakultaeten/mathematisch-naturwissenschaftliche-fakultaet/fachbereiche/informatik/lehrstuehle/computergrafik/lehrstuhl/mitarbeiter/raphael-braun/">Raphael Braun</a>,
              <a href="https://varunjampani.github.io">Varun Jampani</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/celiu/">Ce Liu</a>,
              <a href="https://uni-tuebingen.de/en/faculties/faculty-of-science/departments/computer-science/lehrstuehle/computergrafik/computer-graphics/staff/prof-dr-ing-hendrik-lensch/">Hendrik P. A. Lensch</a>
              <br>
							<em>ICCV</em>, 2021
              <br>
              <a href="https://markboss.me/publication/2021-nerd/">project page</a> /
              <a href="https://www.youtube.com/watch?v=JL-qMTXw9VU">video</a> /
              <a href="https://github.com/cgtuebingen/NeRD-Neural-Reflectance-Decomposition">code</a> /
              <a href="https://arxiv.org/abs/2012.03918">arXiv</a>
              <p></p>
              <p>
              A NeRF-like model that can decompose (and mesh) objects with non-Lambertian reflectances, complex geometry, and unknown illumination.
              </p>
            </td>
          </tr>

          <tr onmouseout="flare_stop()" onmouseover="flare_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='flare_image'>
                  <img src='images/flare_after.jpg' width="160"></div>
                <img src='images/flare_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function flare_start() {
                  document.getElementById('flare_image').style.opacity = "1";
                }

                function flare_stop() {
                  document.getElementById('flare_image').style.opacity = "0";
                }
                flare_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.12485">
                <papertitle>How to Train Neural Networks for Flare Removal</papertitle>
              </a>
              <br>
              <a href="http://yicheng.rice.edu/">Yicheng Wu</a>,
              <a href="https://scholar.google.com/citations?user=BxqV_RsAAAAJ">Qiurui He</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>, <br>
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="https://computationalimaging.rice.edu/team/ashok-veeraraghavan/">Ashok Veeraraghavan</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
							<em>ICCV</em>, 2021
              <br>
              <a href="https://yichengwu.github.io/flare-removal/">project page</a>  / 
              <a href="https://arxiv.org/abs/2011.12485">arXiv</a> 
              <p></p>
              <p>
                Simulating the optics of a camera's lens lets you train a model that removes lens flare from a single image.
              </p>
            </td>
          </tr> 


          <tr onmouseout="inerf_stop()" onmouseover="inerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/inerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/inerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inerf_start() {
                  document.getElementById('inerf_image').style.opacity = "1";
                }
                function inerf_stop() {
                  document.getElementById('inerf_image').style.opacity = "0";
                }
                inerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://yenchenlin.me/inerf/">
                <papertitle>iNeRF: Inverting Neural Radiance Fields for Pose Estimation</papertitle>
              </a>
              <br>
              <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
              <a href="http://www.peteflorence.com/">Pete Florence</a>, 
              <strong>Jonathan T. Barron</strong>,  <br>
              <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
              <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>,
              <a href="https://scholar.google.com/citations?user=_BPdgV0AAAAJ&hl=en">Tsung-Yi Lin</a>
              <br>
              <em>IROS</em>, 2021  
              <br>
              <a href="http://yenchenlin.me/inerf/">project page</a> /
              <a href="https://arxiv.org/abs/2012.05877">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=eQuCZaQN0tI">video</a>
              <p></p>
              <p>Given an image of an object and a NeRF of that object, you can estimate that object's pose.
              </p>
            </td>
          </tr> 


          <tr onmouseout="hypernerf_stop()" onmouseover="hypernerf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='hypernerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hypernerf_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/hypernerf_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function hypernerf_start() {
                  document.getElementById('hypernerf_image').style.opacity = "1";
                }

                function hypernerf_stop() {
                  document.getElementById('hypernerf_image').style.opacity = "0";
                }
                hypernerf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://hypernerf.github.io/">
                <papertitle>HyperNeRF: A Higher-Dimensional Representation
for Topologically Varying Neural Radiance Fields</papertitle>
              </a>
              <br>
							<a href="https://keunhong.com">Keunhong Park</a>,
							<a href="https://utkarshsinha.com">Utkarsh Sinha</a>, 
							<a href="https://phogzone.com/">Peter Hedman</a>,
              <strong>Jonathan T. Barron</strong>,
							<a href="http://sofienbouaziz.com">Sofien Bouaziz</a>, <br>
							<a href="https://www.danbgoldman.com">Dan B Goldman</a>,
							<a href="http://www.ricardomartinbrualla.com">Ricardo Martin-Brualla</a>, 
							<a href="https://homes.cs.washington.edu/~seitz/">Steven M. Seitz</a>
              <br>
              <em>arXiv</em>, 2021 
              <br>
              <a href="https://hypernerf.github.io/">project page</a>
              /
              <a href="https://arxiv.org/abs/2106.13228">arXiv</a>
              <p></p>
              <p>Applying ideas from level set methods to NeRF lets you represent scenes that deform and change shape.</p>
            </td>
          </tr> 

          <tr onmouseout="nerfactor_stop()" onmouseover="nerfactor_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfactor_image'>
                  <img src='images/nerfactor_after.png' width="160"></div>
                <img src='images/nerfactor_before.png' width="160">
              </div>
              <script type="text/javascript">
                function nerfactor_start() {
                  document.getElementById('nerfactor_image').style.opacity = "1";
                }

                function nerfactor_stop() {
                  document.getElementById('nerfactor_image').style.opacity = "0";
                }
                nerfactor_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://people.csail.mit.edu/xiuming/projects/nerfactor/">
              <papertitle>NeRFactor: Neural Factorization of Shape and Reflectance<br>
Under an Unknown Illumination</papertitle>
              </a>
              <br>
              <a href="https://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://boyangdeng.com/">Boyang Deng</a>,<br>
              <a href="https://www.pauldebevec.com/">Paul Debevec</a>,
              <a href="http://billf.mit.edu/">William T. Freeman</a>,
							<strong>Jonathan T. Barron</strong>,
              <br>
              <em>arXiv</em>, 2021 
              <br>
              <a href="https://people.csail.mit.edu/xiuming/projects/nerfactor/">project page</a>
              /
              <a href="https://arxiv.org/abs/2106.01970">arXiv</a>
              /
              <a href="https://www.youtube.com/watch?v=UUVSPJlwhPg">video</a>
              <p></p>
              <p>By placing priors on illumination and materials, we can recover NeRF-like models of the intrinsics of a scene from a single multi-image capture.</p>
            </td>

          <tr onmouseout="ibrnet_stop()" onmouseover="ibrnet_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ibrnet_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/ibrnet_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/ibrnet_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ibrnet_start() {
                  document.getElementById('ibrnet_image').style.opacity = "1";
                }

                function ibrnet_stop() {
                  document.getElementById('ibrnet_image').style.opacity = "0";
                }
                ibrnet_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ibrnet.github.io/">
                <papertitle>IBRNet: Learning Multi-View Image-Based Rendering</papertitle>
              </a>
              <br>
              <a href="https://www.cs.cornell.edu/~qqw/">Qianqian Wang</a>,
              <a href="https://www.linkedin.com/in/zhicheng-wang-96116897/">Zhicheng Wang</a>,
              <a href="https://www.kylegenova.com/">Kyle Genova</a>,
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://scholar.google.com/citations?user=Rh9T3EcAAAAJ&hl=en">Howard Zhou</a>, <br>
              <strong>Jonathan T. Barron</strong>, 
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla</a>,
              <a href="https://www.cs.cornell.edu/~snavely/">Noah Snavely</a>, 
              <a href="https://www.cs.princeton.edu/~funk/">Thomas Funkhouser</a>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://ibrnet.github.io/">project page</a> /
              <a href="https://github.com/googleinterns/IBRNet">code</a> / 
              <a href="https://arxiv.org/abs/2102.13090">arXiv</a>
              <p></p>
              <p>By learning how to pay attention to input images at render time, 
                  we can amortize inference for view synthesis and reduce error rates by 15%.</p>
            </td>
          </tr>

          <tr onmouseout="nerv_stop()" onmouseover="nerv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/hotdog.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/hotdog.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerv_start() {
                  document.getElementById('nerv_image').style.opacity = "1";
                }

                function nerv_stop() {
                  document.getElementById('nerv_image').style.opacity = "0";
                }
                nerv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://pratulsrinivasan.github.io/nerv/">
                <papertitle>NeRV: Neural Reflection and Visibility Fields for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <a href="https://boyangdeng.com/">Boyang Deng</a>,
              <a href="https://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>, <br>
              <a href="http://matthewtancik.com/">Matthew Tancik</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>
              <br>
              <em>CVPR</em>, 2021
              <br>
              <a href="https://pratulsrinivasan.github.io/nerv/">project page</a> /
              <a href="https://www.youtube.com/watch?v=4XyDdvhhjVo">video</a> /
              <a href="https://arxiv.org/abs/2012.03927">arXiv</a>
              <p></p>
              <p>Using neural approximations of expensive visibility integrals lets you recover relightable NeRF-like models.</p>
            </td>
          </tr>


          <tr onmouseout="winr_stop()" onmouseover="winr_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='winr_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/notre_160.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/notre.jpg' width="160">
              </div>
              <script type="text/javascript">
                function winr_start() {
                  document.getElementById('winr_image').style.opacity = "1";
                }
                function winr_stop() {
                  document.getElementById('winr_image').style.opacity = "0";
                }
                winr_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.matthewtancik.com/learnit">
                <papertitle>Learned Initializations for Optimizing Coordinate-Based Neural Representations</papertitle>
              </a>
              <br>
              <a href="http://matthewtancik.com/">Matthew Tancik*</a>,
              <a href="https://bmild.github.io/">Ben Mildenhall*</a>,
              <a href="https://www.linkedin.com/in/terrance-wang/">Terrance Wang</a>,
              <a href="https://www.linkedin.com/in/divi-schmidt-262044180/">Divi Schmidt</a>, <br>
              <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/yirenng.html">Ren Ng</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="http://www.matthewtancik.com/learnit">project page</a> /
              <a href="https://www.youtube.com/watch?v=A-r9itCzcyo">video</a> /
              <a href="https://arxiv.org/abs/2012.02189">arXiv</a> 
              <p></p>
              <p>Using meta-learning to find weight initializations for coordinate-based MLPs allows them to converge faster and generalize better.</p>
            </td>
          </tr>

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfw_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfw_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfw_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerf-w.github.io/">
                <papertitle>NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</papertitle>
              </a>
              <br>
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla*</a>,
              <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ&hl=en">Noha Radwan*</a>,
              <a href="https://research.google/people/105804/">Mehdi S. M. Sajjadi*</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://scholar.google.com/citations?user=FXNJRDoAAAAJ&hl=en">Alexey Dosovitskiy</a>,
              <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://nerf-w.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2008.02268">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=mRAKVQj5LRA">video</a>
              <p></p>
              <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
            </td>
          </tr> 

          <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualrefl_image'>
                  <img src='images/dualrefl_after.jpg' width="160"></div>
                <img src='images/dualrefl_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dualrefl_start() {
                  document.getElementById('dualrefl_image').style.opacity = "1";
                }

                function dualrefl_stop() {
                  document.getElementById('dualrefl_image').style.opacity = "0";
                }
                dualrefl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://sniklaus.com/dualref">
                <papertitle>Learned Dual-View Reflection Removal</papertitle>
              </a>
              <br>
              <a href="http://sniklaus.com/welcome">Simon Niklaus</a>,
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://nealwadhwa.com">Neal Wadhwa</a>,
              <a href="http://rahuldotgarg.appspot.com/">Rahul Garg</a>,
              <a href="http://web.cecs.pdx.edu/~fliu/">Feng Liu</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <br>
              <em>WACV</em>, 2021
              <br>
              <a href="http://sniklaus.com/dualref">project page</a> /
              <a href="https://arxiv.org/abs/2010.00702">arXiv</a>
              <p></p>
              <p>
                Reflections and the things behind them often exhibit parallax, and this lets you remove reflections from stereo pairs.
              </p>
            </td>
          </tr> 


          <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nlt_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nlt_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nlt_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nlt_start() {
                  document.getElementById('nlt_image').style.opacity = "1";
                }

                function nlt_stop() {
                  document.getElementById('nlt_image').style.opacity = "0";
                }
                nlt_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://nlt.csail.mit.edu/">
                <papertitle>Neural Light Transport for Relighting and View Synthesis</papertitle>
              </a>
              <br>
              <a href="http://people.csail.mit.edu/xiuming/">Xiuming Zhang</a>,
              <a href="http://www.seanfanello.it/">Sean Fanello</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="http://kevinkingo.com/">Tiancheng Sun</a>,
              <a href="https://people.csail.mit.edu/tfxue/">Tianfan Xue</a>,
              <a href="https://research.google/people/106687/">Rohit Pandey</a>,
              <a href="https://www.dtic.ua.es/~sorts/">Sergio Orts-Escolano</a>,
              <a href="https://dl.acm.org/profile/99659224296">Philip Davidson</a>,
              <a href="https://scholar.google.com/citations?user=5D0_pjcAAAAJ&hl=en">Christoph Rhemann</a>,
              <a href="http://www.pauldebevec.com/">Paul Debevec</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://cseweb.ucsd.edu/~ravir/">Ravi Ramamoorthi</a>,
              <a href="http://billf.mit.edu/">William T. Freeman</a>
              <br>
              <em>ACM TOG</em>, 2021
              <br>
              <a href="http://nlt.csail.mit.edu/">project page</a> /
              <a href="https://arxiv.org/abs/2008.03806">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=OGEnCWZihHE">video</a>
              <p></p>
              <p>Embedding a convnet within a predefined texture atlas enables simultaneous view synthesis and relighting.</p>
            </td>
          </tr> 




          <tr onmouseout="deepburst_stop()" onmouseover="deepburst_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='deepburst_image'><img src='images/deepburst_after.png'></div>
                <img src='images/deepburst_before.png'>
              </div>
              <script type="text/javascript">
                function deepburst_start() {
                  document.getElementById('deepburst_image').style.opacity = "1";
                }

                function deepburst_stop() {
                  document.getElementById('deepburst_image').style.opacity = "0";
                }
                deepburst_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://drive.google.com/file/d/1GAH8ijyZ7GnoBnQFANEzdXinHrE4vvXn/view?usp=sharing">
                <papertitle>Burst Denoising with Kernel Prediction Networks</papertitle>
              </a>
              <br>
              <a href="https://bmild.github.io/">Ben Mildenhall</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://people.csail.mit.edu/jiawen/">Jiawen Chen</a>,
              <a href="http://www.dsharlet.com/">Dillon Sharlet</a>,
              <a href="http://graphics.stanford.edu/~renng/">Ren Ng</a>, Robert Carroll
              <br>
              <em>CVPR</em>, 2018 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
              <br>
              <a href="https://drive.google.com/file/d/1aqk3Q-L2spjLZh2yRWKUWIDcZkGjQ7US/view?usp=sharing">supplement</a> /
              <a href="https://github.com/google/burst-denoising">code</a> /
              <a href="data/Mildenhall2018.bib">bibtex</a>
              <p></p>
              <p>We train a network to predict linear kernels that denoise noisy bursts from cellphone cameras.</p>
            </td>
          </tr>


    
          <tr onmouseout="ffcc_stop()" onmouseover="ffcc_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ffcc_image'><img src='images/ffcc_after.jpg'></div>
                <img src='images/ffcc_before.jpg'>
              </div>
              <script type="text/javascript">
                function ffcc_start() {
                  document.getElementById('ffcc_image').style.opacity = "1";
                }

                function ffcc_stop() {
                  document.getElementById('ffcc_image').style.opacity = "0";
                }
                ffcc_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/1611.07596">
                <papertitle>Fast Fourier Color Constancy</papertitle>
              </a>
              <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://ai.google/research/people/105312/">Yun-Ta Tsai</a>,
              <br>
              <em>CVPR</em>, 2017
              <br>
              <a href="https://youtu.be/rZCXSfl13rY">video</a> /
              <a href="data/BarronTsaiCVPR2017.bib">bibtex</a> /
              <a href="https://github.com/google/ffcc">code</a> /
              <a href="https://drive.google.com/open?id=0B4nuwEMaEsnmWkJQMlFPSFNzbEk">output</a> /
              <a href="https://blog.google/products/photos/six-tips-make-your-photos-pop/">blog post</a> /
              <a href="https://9to5google.com/2017/03/03/google-photos-auto-white-balance/">p</a><a href="https://www.engadget.com/2017/03/03/google-photos-automatically-fixes-your-pictures-white-balance/">r</a><a href="https://lifehacker.com/google-photos-will-now-automatically-adjust-the-white-b-1793009155">e</a><a href="https://petapixel.com/2017/03/06/google-photos-will-now-automatically-white-balance-snapshots/">s</a><a href="http://www.theverge.com/2017/3/3/14800062/google-photos-auto-white-balance-android">s</a>
              <p></p>
              <p>Color space can be aliased, allowing white balance models to be learned and evaluated in the frequency domain. This improves accuracy by 13-20% and speed by 250-3000x.</p>
              <p>This technology is used by <a href="https://store.google.com/product/pixel_compare">Google Pixel</a>, <a href="https://photos.google.com/">Google Photos</a>, and <a href="https://www.google.com/maps">Google Maps</a>.</p>
            </td>
          </tr>


          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/B3DO.jpg" alt="b3do" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://drive.google.com/file/d/1_S8EQyngbHQrB415o0XkQ4V9SMzdEgWT/view?usp=sharing">
                <papertitle>A Category-Level 3-D Object Dataset: Putting the Kinect to Work</papertitle>
              </a>
              <br>
              <a href="http://www.eecs.berkeley.edu/%7Eallie/">Allison Janoch</a>,
              <a href="http://sergeykarayev.com/">Sergey Karayev</a>,
              <a href="http://www.eecs.berkeley.edu/%7Ejiayq/">Yangqing Jia</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.cs.berkeley.edu/%7Emfritz/">Mario Fritz</a>,
              <a href="http://www.icsi.berkeley.edu/%7Esaenko/">Kate Saenko</a>,
              <a href="http://www.eecs.berkeley.edu/%7Etrevor/">Trevor Darrell</a>
              <br>
              <em>ICCV 3DRR Workshop</em>, 2011
              <br>
              <a href="data/B3DO_ICCV_2011.bib">bibtex</a> /
              <a href="https://drive.google.com/file/d/1qf4-U5RhSw12O7gzQwW66SMQhs2FWYDW/view?usp=sharing">"smoothing" code</a>
              <p>We present a large RGB-D dataset of indoor scenes and investigate ways to improve object detection using depth information.</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Service</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="20"><tbody>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
            <td width="75%" valign="center">
              <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair, Longuet-Higgins Award Committee Member, CVPR 2021</a>
              <br><br>
              <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
              <br><br>
              <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
            </td>
          </tr>
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/cs188.jpg" alt="cs188">
            </td>
            <td width="75%" valign="center">
              <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
              <br>
              <br>
              <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
              <br>
              <br>
              <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
               <a href="https://jonbarron.info/">Website Template </a>,
              
                Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
